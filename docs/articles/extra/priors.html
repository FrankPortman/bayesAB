<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Priors and Bayesian AB Testing • bayesAB</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><meta property="og:title" content="Priors and Bayesian AB Testing">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">bayesAB</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.1.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/extra/priors.html">Priors and Bayesian AB Testing</a>
    </li>
    <li>
      <a href="../../articles/introduction.html">Introduction to bayesAB</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/FrankPortman/bayesAB">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Priors and Bayesian AB Testing</h1>
                        <h4 class="author">Frank Portman - fportman.com - <a href="mailto:frank1214@gmail.com">frank1214@gmail.com</a>
</h4>
            
            <h4 class="date">2019-01-17</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/FrankPortman/bayesAB/blob/master/vignettes/extra/priors.Rmd"><code>vignettes/extra/priors.Rmd</code></a></small>
      <div class="hidden name"><code>priors.Rmd</code></div>

    </div>

    
    
<div id="why-should-we-care-about-priors" class="section level2">
<h2 class="hasAnchor">
<a href="#why-should-we-care-about-priors" class="anchor"></a>Why should we care about priors?</h2>
<p>Most questions I’ve gotten since I released bayesAB have been along the lines of:</p>
<ul>
<li>Why/how is Bayesian AB testing better than Frequentist hypothesis AB testing?</li>
<li>Why do I need priors?</li>
<li>Do I really really really need priors?</li>
<li>How do I choose priors?</li>
</ul>
<p>Question 1 has a few objective and a few subjective answers to it. The main benefits are ones that I’ve already highlighted in the README/vignette of the bayesAB package. To briefly summarize, we get direct probabilities for A &gt; B (rather than p-values) and distributions over the parameter estimates rather than point estimates. Finally, we can also leverage <strong>priors</strong> which help with the low sample size and low base rate problems.</p>
<p>To start, let’s go back to what a <strong>prior</strong> actually is in a Bayesian context. There are countless mathematical resources out there (including part of my previous blog post) so I’ll only about this conceptually. Simply put, a <strong>prior</strong> lets you specify some sort of, ahem, <em>prior</em> information about a certain parameter so that the end <strong>posterior</strong> on that parameter encapsualtes both the <strong>data</strong> you saw and the <strong>prior</strong> you inputted. Priors can come from a variety of places including past experiments, literature, and domain expertise into the problem. <a href="http://www.sumsar.net/blog/2015/11/a-bayesian-model-to-calculate-whether-my-wife-is-pregnant/">See this blogpost</a> for a great example of somebody combining their own past data and literature to form very strong priors.</p>
<p><strong>Priors</strong> can be weak or strong. The weakest prior will be completely <strong>objective</strong> and thus assign an equal probability to each value for the parameter. Examples of this include a Beta(1, 1) prior for the Bernoulli distribution. In these cases, the <strong>posterior</strong> distribution is completely reliant on the <strong>data</strong>. A strong <strong>prior</strong> will convey a very precise belief as to where a parameter’s values may lie. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(bayesAB)

<span class="kw"><a href="../../reference/plotBeta.html">plotBeta</a></span>(<span class="dv">1000</span>, <span class="dv">1000</span>)</code></pre></div>
<p><img src="priors_blog/strong_priors-1.png" width="700.8" style="display: block; margin: auto;"></p>
<p>The stronger the <strong>prior</strong> the more say it has in the <strong>posterior</strong> distribution. Of course, according to the <a href="https://en.wikipedia.org/wiki/Bernstein%E2%80%93von_Mises_theorem">Bernstein–von Mises theorem</a> the <strong>posterior</strong> is effectively independent of the <strong>prior</strong> once a large enough sample size has been reached for the <strong>data</strong>. How quickly this is the case, depends on the strength of your <strong>prior</strong>.</p>
<p>Do you need (weak/strong) <strong>priors</strong>? Not necessarily. You can still leverage the interpretability benefits of Bayesian AB testing even without priors. At worst, you’ll also get slightly more pertinent results since you can parametrize your metrics as the appropriate distribution random variable. However, without <strong>priors</strong> of some kind (and to be clear, not random bullshit priors either) you run into similar issues as with Frequentist AB testing, namely Type 1 and Type 2 errors. A Type 1 error is calling one version better when it really isn’t, and a Type 2 error is calling a better version equal or worse. Both typically arise from low sample size/base rate and are controlled by reaching appropriate sample size as per a <a href="https://en.wikipedia.org/wiki/Statistical_power">power calculation</a>.</p>
<div id="so-what-can-we-do" class="section level3">
<h3 class="hasAnchor">
<a href="#so-what-can-we-do" class="anchor"></a>So what can we do?</h3>
<p>Have no fear! Even without good and/or strong <strong>priors</strong> there are still ways to control for false positives and all that good stuff. We use something called <strong>Expected Posterior Loss</strong> or “based on the current winner, what is the expected loss you would see should you choose wrongly”. If this value is lower than your <strong>threshold of caring</strong> (<code><a href="https://www.rdocumentation.org/packages/base/topics/MathFun">abs(A - b)</a></code>) then you can go ahead and call your test. This value implictly encompasses the uncertainty about your <strong>posteriors</strong>.</p>
<p>Okay cool, that roughly answers Questions 1-4 in some order.</p>
</div>
</div>
<div id="simulation" class="section level2">
<h2 class="hasAnchor">
<a href="#simulation" class="anchor"></a>Simulation</h2>
<p>Let’s do a quick simulation to illustrate some of the above points. Let’s make three examples: weak priors, strong priors, and diffuse priors (quick tip: the <a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffrey’s Prior</a> of a Gamma distribution is Gamma(eps, eps) where eps is smallllll). We’ll be taking 2 x 100 samples from a Poisson distribution with the same <span class="math inline">\(\lambda\)</span> parameters. The strong and weak priors will be centered around this value of 2.3.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/library">library</a></span>(magrittr)

n &lt;-<span class="st"> </span><span class="fl">1e3</span>
out_weaker_priors &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/rep">rep</a></span>(<span class="ot">NA</span>, n)
out_stronger_priors &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/rep">rep</a></span>(<span class="ot">NA</span>, n)
out_diffuse &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/rep">rep</a></span>(<span class="ot">NA</span>, n)

getProb &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(x)<span class="op">$</span>probability<span class="op">$</span>Lambda

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
  A &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Poisson">rpois</a></span>(<span class="dv">100</span>, <span class="fl">2.3</span>)
  B &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/stats/topics/Poisson">rpois</a></span>(<span class="dv">100</span>, <span class="fl">2.3</span>)
  
  out_weaker_priors[i] &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/bayesTest.html">bayesTest</a></span>(A, B, <span class="dt">priors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'shape'</span> =<span class="st"> </span><span class="dv">23</span>, <span class="st">'rate'</span> =<span class="st"> </span><span class="dv">10</span>), <span class="dt">distribution =</span> <span class="st">'poisson'</span>) <span class="op">%&gt;%</span>
<span class="st">    </span>getProb
  
  out_stronger_priors[i] &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/bayesTest.html">bayesTest</a></span>(A, B, <span class="dt">priors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'shape'</span> =<span class="st"> </span><span class="dv">230</span>, <span class="st">'rate'</span> =<span class="st"> </span><span class="dv">100</span>), <span class="dt">distribution =</span> <span class="st">'poisson'</span>) <span class="op">%&gt;%</span>
<span class="st">    </span>getProb
  
  out_diffuse[i] &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/bayesTest.html">bayesTest</a></span>(A, B, <span class="dt">priors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'shape'</span> =<span class="st"> </span><span class="fl">0.00001</span>, <span class="st">'rate'</span> =<span class="st"> </span><span class="fl">0.00001</span>), <span class="dt">distribution =</span> <span class="st">'poisson'</span>) <span class="op">%&gt;%</span>
<span class="st">    </span>getProb
}
  
out_weaker_priors &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/ifelse">ifelse</a></span>(out_weaker_priors <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">|</span><span class="st"> </span>out_weaker_priors <span class="op">&gt;=</span><span class="st"> </span>.<span class="dv">95</span>, <span class="dv">1</span>, <span class="dv">0</span>)
out_stronger_priors &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/ifelse">ifelse</a></span>(out_stronger_priors <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">|</span><span class="st"> </span>out_stronger_priors <span class="op">&gt;=</span><span class="st"> </span>.<span class="dv">95</span>, <span class="dv">1</span>, <span class="dv">0</span>)
out_diffuse &lt;-<span class="st"> </span><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/ifelse">ifelse</a></span>(out_diffuse <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">|</span><span class="st"> </span>out_diffuse <span class="op">&gt;=</span><span class="st"> </span>.<span class="dv">95</span>, <span class="dv">1</span>, <span class="dv">0</span>)</code></pre></div>
<p>Now, A and B shouldn’t have any difference between the two but occasionally we will see a Type 1 error. That’s what the bottom 3 lines are doing. If P(A &gt; B) is &lt;=0.05 or &gt;= .95 we call one of the recipes “significantly” better. Observe what happens with each case of prior.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/mean">mean</a></span>(out_weaker_priors)</code></pre></div>
<pre><code>## [1] 0.086</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/mean">mean</a></span>(out_stronger_priors)</code></pre></div>
<pre><code>## [1] 0.015</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/mean">mean</a></span>(out_diffuse)</code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<p>The diffuse priors have the most Type 1 errors, followed by the weak priors, followed by the strong priors; to be expected.</p>
<p>Finally, we can fit another bayesTest (:D) to determine whether the differences between Type 1 error percents across priors are different from one another.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t1 &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/bayesTest.html">bayesTest</a></span>(out_diffuse, out_weaker_priors, <span class="dt">priors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'alpha'</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">'beta'</span> =<span class="st"> </span><span class="dv">1</span>), <span class="dt">distribution =</span> <span class="st">'bernoulli'</span>)
t2 &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/bayesTest.html">bayesTest</a></span>(out_diffuse, out_stronger_priors, <span class="dt">priors =</span> <span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/c">c</a></span>(<span class="st">'alpha'</span> =<span class="st"> </span><span class="dv">1</span>, <span class="st">'beta'</span> =<span class="st"> </span><span class="dv">1</span>), <span class="dt">distribution =</span> <span class="st">'bernoulli'</span>)

<span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(t1)</code></pre></div>
<p><img src="priors_blog/bern-1.png" width="700.8" style="display: block; margin: auto;"><img src="priors_blog/bern-2.png" width="700.8" style="display: block; margin: auto;"><img src="priors_blog/bern-3.png" width="700.8" style="display: block; margin: auto;"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/graphics/topics/plot">plot</a></span>(t2, <span class="dt">priors =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="priors_blog/bern-4.png" width="700.8" style="display: block; margin: auto;"><img src="priors_blog/bern-5.png" width="700.8" style="display: block; margin: auto;"></p>
<p>As we can see, it’s somewhat clear that the diffuse is worse than the weak and very clear that the diffuse is worse than the stronger priors. Note that in our case I use a diffuse prior of Beta(1, 1) since I have no idea what’s normal going into this simulation.</p>
<p>Finally we can check the output of <code>summary</code> to see if the <strong>Posterior Expected Loss</strong> is within our constraints.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(t1)</code></pre></div>
<pre><code>## Quantiles of posteriors for A and B:
## 
## $Probability
## $Probability$A
##         0%        25%        50%        75%       100% 
## 0.06739519 0.09427062 0.10056094 0.10704886 0.14686119 
## 
## $Probability$B
##         0%        25%        50%        75%       100% 
## 0.05177455 0.08071485 0.08659056 0.09268773 0.13068404 
## 
## 
## --------------------------------------------
## 
## P(A &gt; B) by (0)%: 
## 
## $Probability
## [1] 0.85802
## 
## --------------------------------------------
## 
## Credible Interval on (A - B) / B for interval length(s) (0.9) : 
## 
## $Probability
##          5%         95% 
## -0.07523154  0.46091567 
## 
## --------------------------------------------
## 
## Posterior Expected Loss for choosing B over A:
## 
## $Probability
## [1] 0.01051779</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://www.rdocumentation.org/packages/base/topics/summary">summary</a></span>(t2)</code></pre></div>
<pre><code>## Quantiles of posteriors for A and B:
## 
## $Probability
## $Probability$A
##         0%        25%        50%        75%       100% 
## 0.06315157 0.09416441 0.10047159 0.10700951 0.14641549 
## 
## $Probability$B
##          0%         25%         50%         75%        100% 
## 0.004018659 0.013150062 0.015622492 0.018430066 0.037427719 
## 
## 
## --------------------------------------------
## 
## P(A &gt; B) by (0)%: 
## 
## $Probability
## [1] 1
## 
## --------------------------------------------
## 
## Credible Interval on (A - B) / B for interval length(s) (0.9) : 
## 
## $Probability
##       5%      95% 
## 3.225201 9.223615 
## 
## --------------------------------------------
## 
## Posterior Expected Loss for choosing B over A:
## 
## $Probability
## [1] 0</code></pre>
<p>If the <strong>Posterior Expected Loss</strong> is lower than our threshold for caring on abs(A - B) then we can call this test and accept the current results. The PEL is small in both cases, and possibly 0/NaN for <code>t2</code> so it’s quite clear that priors, even weak ones, have a significant positive effect on Type 1 Errors. Remember that we see this effect partially because our <strong>priors</strong> were of a similar shape to the <strong>data</strong>. If the <strong>priors</strong> and the <strong>data</strong> disagree, the effects might not be so clear cut and you will need more <strong>data</strong> to have a stable <strong>posterior</strong>.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#why-should-we-care-about-priors">Why should we care about priors?</a></li>
      <li><a href="#simulation">Simulation</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Frank Portman.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
